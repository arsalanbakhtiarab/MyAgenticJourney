{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7fFa4oW5dYUkYT/Tb+5Xc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arsalanbakhtiarab/MyAgenticJourney/blob/main/Agentic_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 Agentic AI with LangGraph\n",
        "\n",
        "\n",
        "## 🔧 Step 1: Setup and Installation\n",
        "\n",
        "### Install Required Packages\n",
        "\n",
        "To build and run LangGraph-based agents, we need several key libraries:\n",
        "\n",
        "* `langchain_google_genai`, `langchain_core`, `langchain_community`: Modules that provide the LLM interface and tools\n",
        "* `tavily-python`: For web search integration  \n",
        "* `pydantic`: For data validation and structured outputs\n",
        "* `langgraph`: Core library to construct stateful, agentic workflows\n",
        "\n",
        "```python\n",
        "# Install all required packages\n",
        "%pip install --quiet -U langchain_google_genai langchain_core langchain_community\n",
        "%pip install --quiet -U tavily-python pydantic langgraph\n",
        "```\n",
        "\n",
        "### 📦 Import Essential Libraries\n",
        "\n",
        "```python\n",
        "import os\n",
        "import random\n",
        "from typing import Literal\n",
        "from pprint import pprint\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "```\n",
        "\n",
        "### 🔑 Authentication Setup\n",
        "\n",
        "We retrieve the API key for Google Generative AI and initialize the model:\n",
        "\n",
        "```python\n",
        "# For Google Colab users\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# For local environment users (uncomment if needed)\n",
        "# import getpass\n",
        "# GEMINI_API_KEY = getpass.getpass(\"Enter your Gemini API key: \")\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Test the model connection\n",
        "print(\"Testing LLM connection...\")\n",
        "response = llm.invoke(\"Hello! Can you confirm you're working?\")\n",
        "print(f\"Response: {response.content}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧾 Step 2: Define State and Basic Graph Construction\n",
        "\n",
        "### Define the State Schema\n",
        "\n",
        "The State schema serves as the input schema for all Nodes and Edges in the graph:\n",
        "\n",
        "* Each node returns a new value of the state key `graph_state`\n",
        "* By default, the new value returned by each node will override the prior state value\n",
        "* State must be a Pydantic model for type safety\n",
        "\n",
        "```python\n",
        "class LearningState(BaseModel):\n",
        "    prompt: str\n",
        "\n",
        "# Create an example instance of learning_state\n",
        "state = LearningState(prompt=\"Hello from LangGraph\")\n",
        "print(f\"State: {state}\")\n",
        "print(f\"Prompt: {state.prompt}\")\n",
        "print(f\"State type: {type(state)}\")\n",
        "```\n",
        "\n",
        "### 🔄 Define Nodes\n",
        "\n",
        "Nodes are just Python functions with these characteristics:\n",
        "\n",
        "* The first positional argument is the state (a Pydantic model)\n",
        "* Since the state is a Pydantic model, nodes can access fields like: `state.prompt`\n",
        "* Each node returns a new instance of the state with an updated value\n",
        "* By default, this new value replaces the old one\n",
        "\n",
        "```python\n",
        "def node_1(state: LearningState) -> LearningState:\n",
        "    print(\"--- Executing Node 1 ---\")\n",
        "    return LearningState(prompt=state.prompt + \" I am\")\n",
        "\n",
        "def node_2(state: LearningState) -> LearningState:\n",
        "    print(\"--- Executing Node 2 ---\")\n",
        "    return LearningState(prompt=state.prompt + \" learning\")\n",
        "```\n",
        "\n",
        "### 🔗 Build Linear Graph\n",
        "\n",
        "Edges connect the nodes with these rules:\n",
        "\n",
        "* Normal Edges are used if you want to always go from one node to another\n",
        "* We use the `START` Node, a special node that sends user input to the graph\n",
        "* The `END` Node is a special node that represents a terminal node\n",
        "* Finally, we compile our graph to perform basic checks on the graph structure\n",
        "\n",
        "```python\n",
        "# Build linear graph\n",
        "builder = StateGraph(state_schema=LearningState)\n",
        "\n",
        "# Add nodes\n",
        "builder.add_node(\"node_1\", node_1)\n",
        "builder.add_node(\"node_2\", node_2)\n",
        "\n",
        "# Add simple edges\n",
        "builder.add_edge(START, \"node_1\")\n",
        "builder.add_edge(\"node_1\", \"node_2\")\n",
        "builder.add_edge(\"node_2\", END)\n",
        "\n",
        "# Compile and visualize\n",
        "linear_graph = builder.compile()\n",
        "display(Image(linear_graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# Execute the graph\n",
        "result = linear_graph.invoke({\"prompt\": \"Hi\"})\n",
        "print(f\"Final result: {result}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🔁 Step 3: Conditional Edges and Routing\n",
        "\n",
        "### Understanding Conditional Edges\n",
        "\n",
        "Conditional Edges are used when you want to optionally route between nodes:\n",
        "\n",
        "* Conditional edges are implemented as functions that return the next node to visit\n",
        "* The routing decision is based on the current state\n",
        "* This enables dynamic workflow control based on data or conditions\n",
        "\n",
        "```python\n",
        "def node_happy(state: LearningState) -> LearningState:\n",
        "    print(\"--- Happy Path ---\")\n",
        "    return LearningState(prompt=state.prompt + \" happy\")\n",
        "\n",
        "def node_sad(state: LearningState) -> LearningState:\n",
        "    print(\"--- Sad Path ---\")\n",
        "    return LearningState(prompt=state.prompt + \" sad\")\n",
        "\n",
        "def decide_mood(state: LearningState) -> Literal[\"node_happy\", \"node_sad\"]:\n",
        "    \"\"\"\n",
        "    Routing function that decides which path to take:\n",
        "    * Often, we will use state to decide on the next node to visit\n",
        "    * Here, we do a 50/50 split between happy and sad paths\n",
        "    * Returns the name of the next node to execute\n",
        "    \"\"\"\n",
        "    user_input = state.prompt\n",
        "    \n",
        "    if random.random() < 0.5:\n",
        "        return \"node_happy\"  # 50% of the time, go to happy node\n",
        "    else:\n",
        "        return \"node_sad\"    # 50% of the time, go to sad node\n",
        "```\n",
        "\n",
        "### Build Conditional Graph\n",
        "\n",
        "```python\n",
        "# Build conditional routing graph\n",
        "builder = StateGraph(LearningState)\n",
        "\n",
        "# Add all nodes\n",
        "builder.add_node(\"node_1\", node_1)\n",
        "builder.add_node(\"node_happy\", node_happy)\n",
        "builder.add_node(\"node_sad\", node_sad)\n",
        "\n",
        "# Add routing logic\n",
        "builder.add_edge(START, \"node_1\")\n",
        "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
        "builder.add_edge(\"node_happy\", END)\n",
        "builder.add_edge(\"node_sad\", END)\n",
        "\n",
        "conditional_graph = builder.compile()\n",
        "display(Image(conditional_graph.get_graph().draw_mermaid_png()))\n",
        "\n",
        "# Test multiple executions to see different paths\n",
        "print(\"=== Testing Conditional Routing ===\")\n",
        "for i in range(3):\n",
        "    result = conditional_graph.invoke({\"prompt\": f\"Test {i+1}\"})\n",
        "    print(f\"Execution {i+1}: {result['prompt']}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 💬 Step 4: Working with Messages\n",
        "\n",
        "### Understanding Message Types\n",
        "\n",
        "Chat models can use messages, which capture different roles within a conversation:\n",
        "\n",
        "* `HumanMessage`: Represents a message from the user\n",
        "* `AIMessage`: Represents a message from the chat model  \n",
        "* `SystemMessage`: Instructions for the chat model to guide behavior\n",
        "* `ToolMessage`: Represents output from a tool call\n",
        "\n",
        "Each message can be supplied with:\n",
        "* `content`: Content of the message\n",
        "* `name`: Optionally, a message author\n",
        "* `response_metadata`: Optionally, a dict of metadata\n",
        "\n",
        "```python\n",
        "# Create a conversation with different message types\n",
        "messages = [\n",
        "    AIMessage(content=\"So you said you were researching ocean mammals?\", name=\"Model\"),\n",
        "    HumanMessage(content=\"Yes, that's right.\", name=\"Lance\"),\n",
        "    AIMessage(content=\"Great, what would you like to learn about?\", name=\"Model\"),\n",
        "    HumanMessage(content=\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\")\n",
        "]\n",
        "\n",
        "print(\"=== Message Conversation ===\")\n",
        "for message in messages:\n",
        "    message.pretty_print()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 5: Tools and Function Calling\n",
        "\n",
        "### Understanding Tools\n",
        "\n",
        "Tools are useful whenever you want a model to interact with external systems:\n",
        "\n",
        "* External systems (APIs) often require a particular input schema, not natural language\n",
        "* When we bind an API as a tool, we give the model awareness of the required input schema\n",
        "* The model will choose to call a tool based upon natural language input from the user\n",
        "* It returns an output that adheres to the tool's schema\n",
        "* Many LLM providers support tool calling through LangChain's simple interface\n",
        "\n",
        "### Define Mathematical Tools\n",
        "\n",
        "```python\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers.\n",
        "    \n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "        \n",
        "    Returns:\n",
        "        Product of a and b\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers.\n",
        "    \n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "        \n",
        "    Returns:\n",
        "        Sum of a and b\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"Divide two numbers.\n",
        "    \n",
        "    Args:\n",
        "        a: Dividend\n",
        "        b: Divisor\n",
        "        \n",
        "    Returns:\n",
        "        Result of a divided by b\n",
        "    \"\"\"\n",
        "    if b == 0:\n",
        "        raise ValueError(\"Cannot divide by zero\")\n",
        "    return a / b\n",
        "\n",
        "# Bind tools to the model\n",
        "tools = [add, multiply, divide]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "```\n",
        "\n",
        "### 🔁 Router: Tool Call vs Direct Response\n",
        "\n",
        "We can think of this as a **router**, where the **chat model decides** whether to:\n",
        "\n",
        "* Directly **respond to the user**, or  \n",
        "* **Invoke a tool** based on the user input\n",
        "\n",
        "This is a **simple example of an agent**, where the LLM directs the **control flow**.\n",
        "\n",
        "Key LangGraph concepts for tool integration:\n",
        "* `ToolNode`: A node that performs tool execution\n",
        "* `tools_condition`: A conditional edge that checks if a tool was requested\n",
        "\n",
        "```python\n",
        "def tool_calling_llm(state: MessagesState) -> MessagesState:\n",
        "    \"\"\"Node that invokes the LLM with tool capabilities\"\"\"\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Build tool router graph\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Add routing logic\n",
        "builder.add_edge(START, \"tool_calling_llm\")\n",
        "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
        "builder.add_edge(\"tools\", END)\n",
        "\n",
        "tool_router = builder.compile()\n",
        "display(Image(tool_router.get_graph().draw_mermaid_png()))\n",
        "```\n",
        "\n",
        "### Test Tool Usage\n",
        "\n",
        "```python\n",
        "print(\"=== Tool Router Examples ===\")\n",
        "\n",
        "# Example 1: Math calculation\n",
        "messages = [HumanMessage(content=\"What is 6 multiplied by 7?\")]\n",
        "result = tool_router.invoke({\"messages\": messages})\n",
        "\n",
        "print(\"--- Math Calculation ---\")\n",
        "for message in result['messages']:\n",
        "    message.pretty_print()\n",
        "\n",
        "print(\"\\n--- Addition Example ---\")  \n",
        "messages = [HumanMessage(content=\"Add 15 and 28\")]\n",
        "result = tool_router.invoke({\"messages\": messages})\n",
        "\n",
        "for message in result['messages']:\n",
        "    message.pretty_print()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🤖 Step 6: ReAct Agent with Iterative Tool Use\n",
        "\n",
        "### 🔍 Understanding ReAct Architecture\n",
        "\n",
        "We extend the router to a **generic agent architecture**:\n",
        "\n",
        "* Instead of ending after a tool call, **pass the ToolMessage back to the model**\n",
        "* The model can then:\n",
        "  1. **Call another tool** (act)\n",
        "  2. **Respond directly** (respond)\n",
        "\n",
        "This cycle models the **ReAct architecture**:\n",
        "* **Act**: Model calls a tool\n",
        "* **Observe**: Pass tool output back to model  \n",
        "* **Reason**: Model reasons about tool output and decides next step\n",
        "\n",
        "This loop allows more complex, chained reasoning and tool usage.\n",
        "\n",
        "### 🎯 Goals of ReAct Agent\n",
        "\n",
        "The ReAct agent enables:\n",
        "* **Multi-step problem solving**: Break complex problems into steps\n",
        "* **Tool chaining**: Use output of one tool as input to another\n",
        "* **Iterative reasoning**: Continuously evaluate and adjust approach\n",
        "* **Flexible decision making**: Choose when to use tools vs respond directly\n",
        "\n",
        "### Build ReAct Agent\n",
        "\n",
        "```python\n",
        "# System prompt for agent behavior\n",
        "sys_msg = SystemMessage(content=\"\"\"You are a helpful assistant tasked with performing arithmetic operations.\n",
        "Work step by step and use the available tools to solve complex problems.\n",
        "Show your reasoning process clearly.\"\"\")\n",
        "\n",
        "def assistant(state: MessagesState) -> MessagesState:\n",
        "    \"\"\"Assistant node that processes messages with tool capabilities\"\"\"\n",
        "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
        "\n",
        "# Build ReAct agent graph\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Create the ReAct loop\n",
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
        "builder.add_edge(\"tools\", \"assistant\")  # This creates the iterative loop\n",
        "\n",
        "react_agent = builder.compile()\n",
        "display(Image(react_agent.get_graph(xray=True).draw_mermaid_png()))\n",
        "```\n",
        "\n",
        "### Test Multi-Step Reasoning\n",
        "\n",
        "```python\n",
        "print(\"=== Multi-Step Arithmetic Test ===\")\n",
        "\n",
        "# Complex calculation requiring multiple steps\n",
        "messages = [HumanMessage(content=\"Add 3 and 4, then multiply the result by 2, then divide by 5.\")]\n",
        "result = react_agent.invoke({\"messages\": messages})\n",
        "\n",
        "print(\"ReAct Agent Execution:\")\n",
        "for message in result['messages']:\n",
        "    message.pretty_print()\n",
        "    print(\"---\")\n",
        "\n",
        "print(\"\\n=== Another Complex Example ===\")\n",
        "messages = [HumanMessage(content=\"Calculate (15 + 25) * 3, then divide the result by 6\")]\n",
        "result = react_agent.invoke({\"messages\": messages})\n",
        "\n",
        "for message in result['messages']:\n",
        "    message.pretty_print()\n",
        "    print(\"---\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 💾 Step 7: Agent Memory - Persistent Conversations\n",
        "\n",
        "### Understanding Memory Limitations\n",
        "\n",
        "When running multiple turns **without persistence**, the state is **transient**:\n",
        "\n",
        "* The model forgets past results between conversations\n",
        "* Example:\n",
        "  * User: \"Add 3 and 4.\" → Agent responds \"7\"\n",
        "  * User: \"Multiply that by 2.\" → Agent asks \"Please provide the number...\" because it forgot\n",
        "\n",
        "### Introducing Persistent Memory\n",
        "\n",
        "**MemorySaver** provides persistent memory capabilities:\n",
        "\n",
        "* **MemorySaver**: An in-memory key-value store for graph state\n",
        "* **Checkpoint system**: Automatically saves the graph state after each step\n",
        "* **Thread-based conversations**: Use `thread_id` to maintain separate conversation contexts\n",
        "* **State persistence**: Enables the agent to retain conversation context across multiple invocations\n",
        "\n",
        "This shifts the agent from **transient state** to a **steady state**.\n",
        "\n",
        "### Create Memory-Enabled Agent\n",
        "\n",
        "```python\n",
        "# Create memory checkpointer\n",
        "memory = MemorySaver()\n",
        "react_agent_with_memory = builder.compile(checkpointer=memory)\n",
        "\n",
        "# Configuration for persistent conversation thread\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation_1\"}}\n",
        "\n",
        "print(\"=== Testing Persistent Memory ===\")\n",
        "\n",
        "# First interaction\n",
        "print(\"\\n--- First Turn ---\")\n",
        "result1 = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Calculate 15 + 25\")]},\n",
        "    config\n",
        ")\n",
        "for message in result1['messages']:\n",
        "    message.pretty_print()\n",
        "\n",
        "# Second interaction - should remember previous context\n",
        "print(\"\\n--- Second Turn ---\")\n",
        "result2 = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Now multiply that result by 3\")]},\n",
        "    config\n",
        ")\n",
        "for message in result2['messages']:\n",
        "    message.pretty_print()\n",
        "\n",
        "# Third interaction - testing memory retention\n",
        "print(\"\\n--- Third Turn ---\")\n",
        "result3 = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What was the original sum before multiplication?\")]},\n",
        "    config\n",
        ")\n",
        "for message in result3['messages']:\n",
        "    message.pretty_print()\n",
        "```\n",
        "\n",
        "### Demonstrate Different Conversation Threads\n",
        "\n",
        "```python\n",
        "print(\"=== Different Conversation Threads ===\")\n",
        "\n",
        "# Create a new thread - should not remember previous conversation\n",
        "config_new = {\"configurable\": {\"thread_id\": \"conversation_2\"}}\n",
        "\n",
        "print(\"\\n--- New Thread (should not remember previous conversation) ---\")\n",
        "result_new = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What was the last calculation we did?\")]},\n",
        "    config_new\n",
        ")\n",
        "for message in result_new['messages']:\n",
        "    message.pretty_print()\n",
        "\n",
        "print(\"\\n--- Back to Original Thread ---\")\n",
        "# Switch back to original thread - should remember the context\n",
        "result_original = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can you remind me what we calculated?\")]},\n",
        "    config  # Using original thread_id\n",
        ")\n",
        "for message in result_original['messages']:\n",
        "    message.pretty_print()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Step 8: Advanced Examples and Use Cases\n",
        "\n",
        "### Complex Problem Solving\n",
        "\n",
        "```python\n",
        "print(\"=== Complex Problem Solving ===\")\n",
        "\n",
        "complex_problem = \"\"\"\n",
        "I have a rectangular garden that is 12 meters long and 8 meters wide.\n",
        "Please help me with these calculations:\n",
        "1. Calculate the area of the garden\n",
        "2. If I want to put a fence around it, calculate the perimeter  \n",
        "3. If fencing costs $15 per meter, what's the total cost?\n",
        "\"\"\"\n",
        "\n",
        "result = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=complex_problem)]},\n",
        "    {\"configurable\": {\"thread_id\": \"garden_problem\"}}\n",
        ")\n",
        "\n",
        "for message in result['messages']:\n",
        "    message.pretty_print()\n",
        "```\n",
        "\n",
        "### Error Handling and Edge Cases\n",
        "\n",
        "```python\n",
        "print(\"=== Error Handling Test ===\")\n",
        "\n",
        "# Test division by zero\n",
        "print(\"\\n--- Division by Zero Test ---\")\n",
        "error_test = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What is 10 divided by 0?\")]},\n",
        "    {\"configurable\": {\"thread_id\": \"error_test\"}}\n",
        ")\n",
        "\n",
        "for message in error_test['messages']:\n",
        "    message.pretty_print()\n",
        "\n",
        "# Test with very large numbers\n",
        "print(\"\\n--- Large Number Test ---\")\n",
        "large_test = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Multiply 999999 by 888888\")]},\n",
        "    {\"configurable\": {\"thread_id\": \"large_numbers\"}}\n",
        ")\n",
        "\n",
        "for message in large_test['messages']:\n",
        "    message.pretty_print()\n",
        "```\n",
        "\n",
        "### Multi-Turn Mathematical Conversation\n",
        "\n",
        "```python\n",
        "print(\"=== Multi-Turn Mathematical Conversation ===\")\n",
        "\n",
        "# Start a mathematical conversation thread\n",
        "math_config = {\"configurable\": {\"thread_id\": \"math_conversation\"}}\n",
        "\n",
        "# Turn 1: Start with basic calculation\n",
        "print(\"\\n--- Turn 1 ---\")\n",
        "turn1 = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Let's start with 5 + 3\")]},\n",
        "    math_config\n",
        ")\n",
        "for message in turn1['messages']:\n",
        "    message.pretty_print()\n",
        "\n",
        "# Turn 2: Build on previous result\n",
        "print(\"\\n--- Turn 2 ---\")\n",
        "turn2 = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Square that result\")]},\n",
        "    math_config\n",
        ")\n",
        "for message in turn2['messages']:\n",
        "    message.pretty_print()\n",
        "\n",
        "# Turn 3: Continue the sequence\n",
        "print(\"\\n--- Turn 3 ---\")\n",
        "turn3 = react_agent_with_memory.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Divide by 4 and then add 10\")]},\n",
        "    math_config\n",
        ")\n",
        "for message in turn3['messages']:\n",
        "    message.pretty_print()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 Step 9: Graph Analysis and Debugging\n",
        "\n",
        "### Visualize Graph Structure\n",
        "\n",
        "Understanding your graph structure is crucial for debugging and optimization:\n",
        "\n",
        "* **Nodes**: The processing units of your graph\n",
        "* **Edges**: The connections and flow control\n",
        "* **State flow**: How data moves through the graph\n",
        "* **Conditional logic**: Where decisions are made\n",
        "\n",
        "```python\n",
        "print(\"=== Graph Structure Analysis ===\")\n",
        "\n",
        "# Show detailed graph structure\n",
        "graph_dict = react_agent_with_memory.get_graph()\n",
        "print(f\"Nodes: {list(graph_dict.nodes.keys())}\")\n",
        "print(f\"Edges: {len(graph_dict.edges)} connections\")\n",
        "\n",
        "# Display both normal and X-ray views\n",
        "print(\"\\n--- Normal View ---\")\n",
        "display(Image(react_agent_with_memory.get_graph().draw_mermaid_png()))\n",
        "\n",
        "print(\"\\n--- X-Ray View (shows internal structure) ---\")\n",
        "display(Image(react_agent_with_memory.get_graph(xray=True).draw_mermaid_png()))\n",
        "```\n",
        "\n",
        "### Memory State Inspection\n",
        "\n",
        "```python\n",
        "print(\"=== Memory State Inspection ===\")\n",
        "\n",
        "# Check what's stored in memory for different conversations\n",
        "for thread_name, thread_id in [\n",
        "    (\"Garden Problem\", \"garden_problem\"),\n",
        "    (\"Math Conversation\", \"math_conversation\"),\n",
        "    (\"Error Test\", \"error_test\")\n",
        "]:\n",
        "    try:\n",
        "        thread_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "        thread_state = react_agent_with_memory.get_state(thread_config)\n",
        "        \n",
        "        print(f\"\\n--- {thread_name} Thread ---\")\n",
        "        print(f\"State keys: {list(thread_state.values.keys())}\")\n",
        "        \n",
        "        messages = thread_state.values.get('messages', [])\n",
        "        print(f\"Number of messages: {len(messages)}\")\n",
        "        \n",
        "        if messages:\n",
        "            print(\"Last message:\")\n",
        "            print(f\"  Type: {type(messages[-1]).__name__}\")\n",
        "            print(f\"  Content: {messages[-1].content[:100]}...\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"No state found for {thread_name}: {e}\")\n",
        "```\n",
        "\n",
        "### Performance Analysis\n",
        "\n",
        "```python\n",
        "print(\"=== Performance Analysis ===\")\n",
        "\n",
        "import time\n",
        "\n",
        "# Test execution time for different complexity levels\n",
        "test_cases = [\n",
        "    \"Add 2 and 3\",\n",
        "    \"Multiply 4 by 5, then add 10\",\n",
        "    \"Add 10 and 15, multiply by 2, divide by 5, then add 3\"\n",
        "]\n",
        "\n",
        "for i, test_case in enumerate(test_cases, 1):\n",
        "    print(f\"\\n--- Test Case {i}: {test_case} ---\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    result = react_agent_with_memory.invoke(\n",
        "        {\"messages\": [HumanMessage(content=test_case)]},\n",
        "        {\"configurable\": {\"thread_id\": f\"perf_test_{i}\"}}\n",
        "    )\n",
        "    end_time = time.time()\n",
        "    \n",
        "    execution_time = end_time - start_time\n",
        "    num_messages = len(result['messages'])\n",
        "    \n",
        "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
        "    print(f\"Number of messages: {num_messages}\")\n",
        "    print(f\"Final result: {result['messages'][-1].content}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Step 10: Summary and Key Concepts\n",
        "\n",
        "### What We've Built\n",
        "\n",
        "Throughout this tutorial, we've constructed increasingly sophisticated AI agents:\n",
        "\n",
        "1. **Basic State Management**:\n",
        "   * Created graphs with custom state schemas\n",
        "   * Learned how state flows through nodes\n",
        "   \n",
        "2. **Conditional Routing**:\n",
        "   * Implemented decision-making logic in graphs\n",
        "   * Built dynamic workflow control\n",
        "   \n",
        "3. **Tool Integration**:\n",
        "   * Connected external functions to LLM capabilities\n",
        "   * Created intelligent tool selection\n",
        "   \n",
        "4. **ReAct Architecture**:\n",
        "   * Built iterative reasoning and acting loops\n",
        "   * Enabled multi-step problem solving\n",
        "   \n",
        "5. **Persistent Memory**:\n",
        "   * Enabled multi-turn conversations with context retention\n",
        "   * Implemented thread-based conversation management\n",
        "\n",
        "### Key LangGraph Concepts\n",
        "\n",
        "**Core Components:**\n",
        "* **StateGraph**: Core graph construction class for building workflows\n",
        "* **Nodes**: Python functions that process and transform state\n",
        "* **Edges**: Connections between nodes (simple and conditional)\n",
        "* **MessagesState**: Built-in state schema for chat applications\n",
        "* **START/END**: Special nodes for graph entry and exit points\n",
        "\n",
        "**Advanced Features:**\n",
        "* **ToolNode**: Pre-built node for tool execution\n",
        "* **tools_condition**: Conditional edge for tool call routing\n",
        "* **Checkpointer**: Memory system for persistent state\n",
        "* **MemorySaver**: In-memory storage for conversation history\n",
        "\n",
        "### Architecture Patterns\n",
        "\n",
        "**Router Pattern:**\n",
        "* Simple decision-making between direct response and tool use\n",
        "* Good for straightforward tool selection scenarios\n",
        "\n",
        "**ReAct Pattern:**\n",
        "* Iterative reasoning, acting, and observing cycle\n",
        "* Enables complex multi-step problem solving\n",
        "* Supports tool chaining and adaptive behavior\n",
        "\n",
        "**Memory-Enhanced Agent:**\n",
        "* Persistent context across conversation turns\n",
        "* Thread-based conversation management\n",
        "* Enables sophisticated multi-turn interactions\n",
        "\n",
        "### Production Considerations\n",
        "\n",
        "**Scalability:**\n",
        "* Consider database checkpointers for production memory needs\n",
        "* Implement proper error handling and retry mechanisms\n",
        "* Monitor token usage and API costs\n",
        "\n",
        "**Security:**\n",
        "* Validate tool inputs and outputs\n",
        "* Implement proper authentication for tool access\n",
        "* Consider rate limiting and usage quotas\n",
        "\n",
        "**Observability:**\n",
        "* Use LangSmith for production tracing\n",
        "* Implement logging for debugging and monitoring\n",
        "* Track performance metrics and user satisfaction\n",
        "\n",
        "### Next Steps and Extensions\n",
        "\n",
        "To extend this tutorial, consider exploring:\n",
        "\n",
        "**Advanced Agent Architectures:**\n",
        "* Multi-agent systems with role specialization\n",
        "* Hierarchical agents with delegation patterns\n",
        "* Collaborative agents for complex problem solving\n",
        "\n",
        "**Tool Integration:**\n",
        "* Custom APIs and external service integration\n",
        "* Database query tools and data analysis capabilities\n",
        "* Web scraping and real-time information gathering\n",
        "\n",
        "**Production Deployment:**\n",
        "* Containerization and cloud deployment\n",
        "* Load balancing and scaling strategies\n",
        "* Monitoring and alerting systems\n",
        "\n",
        "**Advanced Features:**\n",
        "* Custom checkpointers for different storage backends\n",
        "* Streaming responses for real-time interactions\n",
        "* Integration with vector databases for RAG applications\n",
        "\n",
        "```python\n",
        "print(\"🎉 Tutorial Complete!\")\n",
        "print(\"You now have a comprehensive understanding of LangGraph agentic AI.\")\n",
        "print(\"\\nKey achievements:\")\n",
        "print(\"✅ Built state-driven AI workflows\")\n",
        "print(\"✅ Implemented tool-calling agents\")\n",
        "print(\"✅ Created ReAct reasoning loops\")\n",
        "print(\"✅ Added persistent memory capabilities\")\n",
        "print(\"✅ Learned debugging and analysis techniques\")\n",
        "print(\"\\n🚀 Ready to build your own intelligent agents!\")\n",
        "```"
      ],
      "metadata": {
        "id": "PB66KAnuT8IM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qrqHAquIYIov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlTqn2SlVvSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}